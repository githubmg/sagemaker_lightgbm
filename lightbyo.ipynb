{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade sagemaker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Build an image that can do training and inference in SageMaker\n",
      "# This is a Python 2 image that uses the nginx, gunicorn, flask stack\n",
      "# for serving inferences in a stable way.\n",
      "\n",
      "FROM ubuntu:18.04\n",
      "\n",
      "MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      "\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
      "         wget \\\n",
      "         python \\\n",
      "         python3.6 \\\n",
      "         nginx \\\n",
      "         ca-certificates \\\n",
      "         libgcc-5-dev \\\n",
      "         build-essential \\\n",
      "         python3-dev \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "\n",
      "# Symlink /usr/bin/python to the python version we're building for.\n",
      "RUN rm /usr/bin/python && ln -s /usr/bin/python3.6 /usr/bin/python\n",
      "\n",
      "# Here we get all python packages.\n",
      "# There's substantial overlap between scipy and numpy that we eliminate by\n",
      "# linking them together. Likewise, pip leaves the install caches populated which uses\n",
      "# a significant amount of space. These optimizations save a fair amount of space in the\n",
      "# image, which reduces start up time.\n",
      "RUN wget https://bootstrap.pypa.io/3.3/get-pip.py && python3.6 get-pip.py\n",
      "RUN pip install --upgrade pip && \\\n",
      " pip3 install lightgbm==3.1.0 pandas==1.0.5 scikit-learn==0.23.1 flask  gunicorn && \\\n",
      " pip3 install gevent --pre && \\\n",
      " rm -rf /root/.cache\n",
      "\n",
      "# Set some environment variables. PYTHONUNBUFFERED keeps Python from buffering our standard\n",
      "# output stream, which means that logs can be delivered to the user quickly. PYTHONDONTWRITEBYTECODE\n",
      "# keeps Python from writing the .pyc files which are unnecessary in this case. We also update\n",
      "# PATH so that the train and serve programs are found when the container is invoked.\n",
      "\n",
      "ENV PYTHONUNBUFFERED=TRUE\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      "ENV PATH=\"/opt/program:${PATH}\"\n",
      "\n",
      "# Set up the program in the image\n",
      "COPY lgb /opt/program\n",
      "WORKDIR /opt/program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat container/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3 prefix\n",
    "\n",
    "# Define IAM role\n",
    "import boto3\n",
    "import re\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "from io import StringIO\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sess = sage.Session()\n",
    "role = get_execution_role()\n",
    "prefix = 'lgb-model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Sending build context to Docker daemon  10.41MB\n",
      "Step 1/11 : FROM ubuntu:18.04\n",
      " ---> 56def654ec22\n",
      "Step 2/11 : MAINTAINER Amazon AI <sage-learner@amazon.com>\n",
      " ---> Using cache\n",
      " ---> d72bea90662d\n",
      "Step 3/11 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          python          python3.6          nginx          ca-certificates          libgcc-5-dev          build-essential          python3-dev     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> 988e8e6e5e79\n",
      "Step 4/11 : RUN rm /usr/bin/python && ln -s /usr/bin/python3.6 /usr/bin/python\n",
      " ---> Using cache\n",
      " ---> ef7de9e576eb\n",
      "Step 5/11 : RUN wget https://bootstrap.pypa.io/3.3/get-pip.py && python3.6 get-pip.py\n",
      " ---> Using cache\n",
      " ---> 8a669529e160\n",
      "Step 6/11 : RUN pip install --upgrade pip &&  pip3 install lightgbm==3.1.0 pandas==1.0.5 scikit-learn==0.23.1 flask  gunicorn &&  pip3 install gevent --pre &&  rm -rf /root/.cache\n",
      " ---> Using cache\n",
      " ---> 24014bd7a783\n",
      "Step 7/11 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 7d2d689f7b96\n",
      "Step 8/11 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> f063bf601be6\n",
      "Step 9/11 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 8e2c2234826e\n",
      "Step 10/11 : COPY lgb /opt/program\n",
      " ---> Using cache\n",
      " ---> b0c790bf409b\n",
      "Step 11/11 : WORKDIR /opt/program\n",
      " ---> Using cache\n",
      " ---> b04cae1d58b1\n",
      "Successfully built b04cae1d58b1\n",
      "Successfully tagged lgb-model:latest\n",
      "The push refers to repository [452432741922.dkr.ecr.us-east-1.amazonaws.com/lgb-model]\n",
      "fdb70606dd1f: Preparing\n",
      "380e79e86c11: Preparing\n",
      "9c9e33cf9f6d: Preparing\n",
      "2be3574fab63: Preparing\n",
      "99567b1c79ff: Preparing\n",
      "7a694df0ad6c: Preparing\n",
      "3fd9df553184: Preparing\n",
      "805802706667: Preparing\n",
      "3fd9df553184: Waiting\n",
      "805802706667: Waiting\n",
      "7a694df0ad6c: Waiting\n",
      "2be3574fab63: Layer already exists\n",
      "99567b1c79ff: Layer already exists\n",
      "9c9e33cf9f6d: Layer already exists\n",
      "380e79e86c11: Layer already exists\n",
      "fdb70606dd1f: Layer already exists\n",
      "7a694df0ad6c: Layer already exists\n",
      "805802706667: Layer already exists\n",
      "3fd9df553184: Layer already exists\n",
      "latest: digest: sha256:004bd23cfb486dc010de8b1ed10ee0c53fba5926bbf97791fbb214fb3a83885a size: 1994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "# The name of our algorithm\n",
    "algorithm_name=lgb-model\n",
    "\n",
    "cd container\n",
    "\n",
    "chmod +x lgb/train\n",
    "chmod +x lgb/serve\n",
    "\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${algorithm_name}:latest\"\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "aws ecr describe-repositories --repository-names \"${algorithm_name}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${algorithm_name}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Build the docker image locally with the image name and then push it to ECR\n",
    "# with the full name.\n",
    "\n",
    "docker build  -t ${algorithm_name} .\n",
    "docker tag ${algorithm_name} ${fullname}\n",
    "\n",
    "docker push ${fullname}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('titanic.csv',sep='|')\n",
    "df = df.drop(['PassengerId','Cabin','Ticket','Name'],axis=1)\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('data/train.csv',index=False)\n",
    "df_test.to_csv('data/test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-452432741922/lgb-model/training/train.csv'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.upload_data('data/train.csv', key_prefix=prefix + '/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = f's3://{sess.default_bucket()}/{prefix}/training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input = {'training': data_location}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-18 13:51:43 Starting - Starting the training job...\n",
      "2020-11-18 13:51:45 Starting - Launching requested ML instances......\n",
      "2020-11-18 13:53:01 Starting - Preparing the instances for training......\n",
      "2020-11-18 13:54:07 Downloading - Downloading input data\n",
      "2020-11-18 13:54:07 Training - Downloading the training image...\n",
      "2020-11-18 13:54:40 Training - Training image download completed. Training in progress..\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34m['/opt/ml/input/data/training/train.csv']\u001b[0m\n",
      "\u001b[34mcsv parsed\u001b[0m\n",
      "\u001b[34mmodel defined\u001b[0m\n",
      "\u001b[34mCross validation AUC 0.8451\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2020-11-18 13:54:52 Uploading - Uploading generated training model\n",
      "2020-11-18 13:54:52 Completed - Training job completed\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/lgb-model:latest'.format(account, region)\n",
    "\n",
    "lgb = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.c4.2xlarge',\n",
    "                       output_path=\"s3://{}/output\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "lgb.fit(s3_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import csv_serializer\n",
    "predictor = lgb.deploy(1, 'ml.m4.xlarge', serializer=csv_serializer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[:,1:].to_csv('data/x_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "\n",
    "endpoint_name = predictor.endpoint_name                               # Your endpoint name.\n",
    "content_type = \"text/csv\"                                        # The MIME type of the input data in the request body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, \n",
    "    ContentType=content_type,\n",
    "    Body=open('data/x_test.csv', 'rb')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_scores = [eval(pred)[1] for pred in list(preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.225</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83.475</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.350</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch     Fare Embarked\n",
       "0         0       3    male   NaN      0      0    7.225        C\n",
       "1         1       1  female  35.0      1      0   83.475        S\n",
       "2         1       2  female  30.0      0      0   12.350        Q\n",
       "3         1       1  female  14.0      1      2  120.000        S\n",
       "4         1       1  female  38.0      0      0   80.000      NaN"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846657929226736"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(test_data.iloc[:,0],prob_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional cleanup\n",
    "When you're done with the endpoint, you'll want to clean it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
